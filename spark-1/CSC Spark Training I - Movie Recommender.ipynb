{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib.request as urllib\n",
    "# u.data -- The full u data set, 100000 ratings by 943 users on 1682 item. \n",
    "          # Each user has rated at least 20 movies.  Users and items are numbered consecutively from 1. \n",
    "          # The data is randomly ordered. This is a tab separated list of user id | item id | rating | timestamp \n",
    "urllib.urlretrieve (\"http://files.grouplens.org/datasets/movielens/ml-100k/u.data\", \"u.data\")\n",
    "# u.item     -- Information about the items (movies); this is a tab separated list of\n",
    "              # movie id | movie title | release date | video release date | IMDb URL |\n",
    "              # unknown | Action | Adventure | Animation | Children's | Comedy | Crime | Documentary |# Drama | Fantasy |Film-Noir | Horror | Musical | Mystery | Romance | Sci-Fi |Thriller | War | Western |\n",
    "              # The last 19 fields are the genres, a 1 indicates the movie is of that genre, a 0 indicates it is not\n",
    "              # The movie ids are the ones used in the u.data data set\n",
    "urllib.urlretrieve (\"http://files.grouplens.org/datasets/movielens/ml-100k/u.item\", \"u.item\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The aim of this exercise is to recommend movies to the users.The exercise is divided into three parts. \n",
    "#### In the first part , you will preprocess the data, transform it into a meaningful format and use mathematical calculations to recommend. \n",
    "#### In the second part, we will use Machine learning methods to recommend on a much more efficient way.\n",
    "#### In the third part, you will recommend movies for yourself based on the ratings you supply manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 A. Create the ratings and movies RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratings = sc.textFile('u.data', 20)\n",
    "movies = sc.textFile('u.item', 20)\n",
    "\n",
    "print(ratings.take(1))\n",
    "print(movies.take(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 B. Feature Extraction: Extracting the relevant features for our problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write down the code for parsing the ratings of the above generated RDD called ratings\n",
    "def ratings_parse(x):\n",
    "    \"\"\"\n",
    "    Returns: (user_id, movie_id(item_id), rating)\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "def movies_parse(x):\n",
    "    \"\"\"\n",
    "    Returns: (movie_id, movie_title)\n",
    "    \"\"\"\n",
    "\n",
    "ratingsRDD = ratings.map(ratings_parse).cache()\n",
    "print(ratingsRDD.take(5))\n",
    "print(ratingsRDD.count())\n",
    "\n",
    "moviesRDD = movies.map(movies_parse).cache()\n",
    "print(moviesRDD.take(5))\n",
    "print(moviesRDD.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 C. First, we will try to recommend movies to the general public and the very basic way is to show all the movies which have high average ratings. We have to display the name, number of ratings, and the average rating of atleast 20 movies with the highest average rating. We should also filter our records based on a specific review threshold i.e. we need only select movies which have total number of reviews above a certain threshold value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You need to implement a helper function which can help in the desired mathematical calculations\n",
    "def getCountsAndAverages(movieIDandRatingsItem):\n",
    "    \"\"\" Calculate average rating of a movie\n",
    "    Args:\n",
    "        movieIDandRatingsItem: (movie_id, (rating1, rating2, ...))\n",
    "    Returns:\n",
    "        (movie_id, (total number of ratings, averageRating))\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -> 1 D. Bring all the reviews for a movie together and then using the above helper function calculate the total count of ratings and average rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Map the ratingsRDD in such a way that it contains only (movie_id, rating)\n",
    "# Then bring all the ratings for a particular movie_id together\n",
    "# movieIDsWithRatingsRDD = .....\n",
    "# print(movieIDsWithRatingsRDD.mapValues(list).take(1))  # [(movie_id, [rating1, rating2 ....])]\n",
    "\n",
    "\n",
    "# Use the helper function getCountsAndAverages to get the total number of ratings for a particular movie and the average of of them\n",
    "# movieIDsWithAvgRatingsRDD = .....\n",
    "# print(movieIDsWithAvgRatingsRDD.take(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  -> 1 E. Attach the name of the movie in the movieIDsWithAvgRatings RDD using moviesRDD which contains the movie name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Attach the name from the moviesRDD to moviesIDsWithAvgRatingsRDD first\n",
    "# _movieNameWithAvgRatingsRDD = ....\n",
    "# print(_movieNameWithAvgRatingsRDD.take(1))  # (movie_id, (movie name, (total_ratings, avg_rating)))\n",
    "\n",
    "# Transform the RDD into this form -> (average rating, movie name, number of ratings)\n",
    "# movieNameWithAvgRatingsRDD = ....\n",
    "# print(movieNameWithAvgRatingsRDD.take(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -> 1 F. Selecting only those movies who have more than 200 reviews to appeal to a broader audience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First select only those records where the total number of reviews are greater than the threshold which is 200\n",
    "# And then sort the final results by avg ratings in descending orders so that the highest avg rating is on the top\n",
    "# Then show first 20 records\n",
    "# movieLimitedAndSortedByRatingRDD = ....\n",
    "# print(movieLimitedAndSortedByRatingRDD.take(20))  # Top 20 Movies for general public"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Now with a more advanced approach we can do tackle the same problem in a more efficient way with one of the Machine learning techniques known as Collaborative filtering. Benefits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use the ALS algorithm for performing Collaborative filtering\n",
    "from pyspark.mllib.recommendation import ALS, Rating\n",
    "# Divide the dataset into three parts as exlained in the slides\n",
    "# ratingsRDD -> (movie_id, user_id, rating)\n",
    "trainingRDD, validationRDD, testRDD = ratingsRDD.randomSplit([6, 2, 2], seed=0)\n",
    "print(validationRDD.take(1))\n",
    "\n",
    "# Build the recommendation model using Alternating Least Squares\n",
    "ranks = [2, 3, 4, 8, 12]  # Rank is a factor which can be tuned to get the best model for our dataset\n",
    "numIterations = 5\n",
    "regularizationParameter = 0.1\n",
    "for rank in ranks:\n",
    "    model = ALS.train(trainingRDD, rank, numIterations, lambda_=regularizationParameter)\n",
    "\n",
    "    # Evaluate the model on training data\n",
    "    validation_data = validationRDD.map(lambda p: (p[0], p[1]))\n",
    "    predictions = model.predictAll(validation_data).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "    ratesAndPreds = validationRDD.map(lambda r: ((r[0], r[1]), r[2])).join(predictions)\n",
    "    MSE = ratesAndPreds.map(lambda r: (r[1][0] - r[1][1])**2).mean()\n",
    "    print(\"Mean Squared Error = \" + str(MSE))\n",
    "    \n",
    "print('Predictions RDD: ', predictions.take(1))\n",
    "print('Ratings and Predictions combined RDD: ', ratesAndPreds.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bestRank = ....  # Fill the best rank by observing the errors from several runs\n",
    "myModel = ALS.train(trainingRDD, bestRank, seed=0, iterations=numIterations,\n",
    "                      lambda_=regularizationParameter)\n",
    "testForPredictingRDD = testRDD.map(lambda item: (item[0], item[1]) )  # (user, movie, rating) -> (user, movie)\n",
    "predictedTestRDD = myModel.predictAll(testForPredictingRDD)\n",
    "# Check how does it look like after predicting from the model\n",
    "predictedTestRDD.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate average rating value of all the ratings for the whole predicted test RDD\n",
    "predictedTestRDD.map(lambda item: item[2]).reduce(lambda a,b: a+b) / predictedTestRDD.count() # item[2] = ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testRDD.take(2) # verify again how it looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate average ratings for the test RDD\n",
    "testRDD.map(lambda item: item[2]).reduce(lambda a,b: a+b) / testRDD.count() # item[2] = ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. In this section you will use the above demonstration to calculate recommendations for yourself. You need to provide manual ratings to at least 10 of the movies from the list and then do the same step of training and testing steps again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Execute this section to get the list of movies which need to select from\n",
    "print('List of movies with maximum number of ratings')\n",
    "print('(average rating, movie name, number of reviews)')\n",
    "for ratingsTuple in movieLimitedAndSortedByRatingRDD.take(50):\n",
    "    print(ratingsTuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "moviesRDD.take(2)  # Verify again what moviesRDD looks like (movie_id, movie_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_user_id = 0  # This is your user id , do not change it\n",
    "\n",
    "# Note that the movie IDs are the *last* number on each line. A common error was to use the number of ratings as the movie ID.\n",
    "myRatedMoviesName = [\n",
    "    (myUserID, u'' , 0),\n",
    "    (myUserID, u'' , 0),\n",
    "    (myUserID, u'' , 0),\n",
    "    (myUserID, u'', 0),\n",
    "    (myUserID, u'', 0),\n",
    "    (myUserID, u'', 0),\n",
    "    (myUserID, u'', 0),\n",
    "    (myUserID, u'', 0),\n",
    "    (myUserID, u'', 0),\n",
    "    (myUserID, u'', 0),\n",
    "    ]\n",
    "myRatedMovies = []\n",
    "# We need to pull movie_ids for the movies that you have entered from the moviesRDD\n",
    "for (uid, name, rating) in myRatedMoviesName:\n",
    "    movie_id = moviesRDD.filter(lambda item: item[1] == name).take(1)[0][0]\n",
    "    myRatedMovies.append( (uid, movie_id, float(rating)) )\n",
    "# Convert the python list into RDD     \n",
    "myRatingsRDD = sc.parallelize(myRatedMovies)\n",
    "print(myRatingsRDD.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use the union() function of spark to append the contents of myRatingsRDD to trainingRDD\n",
    "# trainingWithMyRatingsRDD = ....\n",
    "# Then train the model with the new RDD using same old parameters as before\n",
    "# myRatingsModel = ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now select all movies except the ones you rated in myRatedMovies array. \n",
    "# Hint: you can run a for loop with lambda to filter and select only the movies which were not in the myRatedMovies array \n",
    "# _myUnratedMoviesRDD = ....\n",
    "# print('_myUnratedMoviesRDD', _myUnratedMoviesRDD.take(1))  # (movie_id, movie_name)\n",
    "\n",
    "# Transform the above result into an RDD which looks like (my_user_id, movie_id)\n",
    "# myUnratedMoviesRDD = ....\n",
    "# print('myUnratedMoviesRDD ', myUnratedMoviesRDD.take(1))\n",
    "\n",
    "# Remember how we converted testRDD to testForPredictingRDD by removing the ratings field from the testRDD \n",
    "# myUnratedMovies now has an user_id (my_user_id) and movie_id.\n",
    "# Hence now you can use myUnratedMoviesRDD with myRatingsModel to predict your ratings for the movies\n",
    "\n",
    "# predictedRatingsRDD = ....\n",
    "# predictedRatingsRDD.take(2) # IMPORTANT, This RDD is not made up of tuples now, it is an RDD of 'Rating' objects!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Transform movieIDsWithAvgRatingsRDD from section(1 D)\n",
    "# Remember it has the form (MovieID, (number of ratings, average rating)), transform into an RDD of the form (MovieID, number of ratings)\n",
    "# movieCountsRDD = ....\n",
    "\n",
    "# Transform predictedRatingsRDD into an RDD with entries that are pairs of the form (Movie ID, Predicted Rating)\n",
    "# predictedMoviesWithRatingsRDD = ....\n",
    "\n",
    "# Use predictedMoviesWithRatingsRDD and movieCountsRDD (created above) to yield a new RDD of the form (Movie ID, (Predicted Rating, number of ratings))\n",
    "# predictedMoviesWithRatingsAndCountsRDD  = ....\n",
    "\n",
    "# predictedMoviesWithRatingsAndCountsRDD.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Select movies from predictedMoviesWithRatingsAndCountsRDD with number of ratings more than say, 150\n",
    "# Then, Using PredictedMoviesWithRatingsAndCountsRDD and moviesRDD (which has the movie name) we need to yield an RDD of the form\n",
    "# (Predicted Rating, Movie Name, number of ratings)\n",
    "\n",
    "# predictedMoviesWithRatingsCountsAndNamesRDD = ....\n",
    "# print('predictedMoviesWithRatingsCountsAndNamesRDD ', predictedMoviesWithRatingsCountsAndNamesRDD.take(1)) \n",
    "\n",
    "\n",
    "# ratingsWithNamesRDD = ....                      \n",
    "# print('ratingsWithNamesRDD ', ratingsWithNamesRDD.take(1))\n",
    "\n",
    "# use takeOrdered instead of take and pass the lambda function in key to sort it in descending order (select 20 movies)\n",
    "# ratingsWithNamesRDD.takeOrdered(20, key=lambda ....)\n",
    "\n",
    "# These are Highest rated 20 movies (Predicted Recommendations) with reviews > 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
